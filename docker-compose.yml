services:
  # Ollama - Modelos de IA locales
  ollama:
    image: ollama/ollama:latest
    container_name: rewindday-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      # Aumentar tiempo de carga para modelos grandes (ej. 10 minutos)
      - OLLAMA_LOAD_TIMEOUT=10m
      # Opcional: limitar modelos cargados en memoria
      - OLLAMA_MAX_LOADED_MODELS=1
      # Mantener conexiones vivas m√°s tiempo (opcional)
      - OLLAMA_KEEP_ALIVE=10m
    networks:
      - rewindday-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 600s
    restart: unless-stopped
    pull_policy: always

  # API de IA (FastAPI)
  ai:
    build:
      context: ./apps/ai
      dockerfile: Dockerfile
    container_name: rewindday-ai
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_API_URL=http://ollama:11434
      - OLLAMA_MODEL=deepseek-r1:8b
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
    depends_on:
      ollama:
        condition: service_started
    networks:
      - rewindday-network
    volumes:
      - ./apps/ai/app:/app/app
    restart: unless-stopped
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

networks:
  rewindday-network:
    driver: bridge

volumes:
  ollama_data:
